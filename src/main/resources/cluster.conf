akka {
  loglevel = INFO
  
  actor {
    provider = cluster
    
    serializers {
      ping = "blog.typed.cluster.scaladsl.PingSerializer"
      seqNr = "blog.typed.cluster.scaladsl.SequenceNumberSerializer"
      blog = "blog.typed.persistence.scaladsl.BlogSerializer"
    }
    serialization-bindings {
      "blog.typed.cluster.scaladsl.Routee$Ping" = ping
      "blog.typed.cluster.scaladsl.Routee$Pong$" = ping
      
      "blog.typed.cluster.scaladsl.SequenceNumberGenerator$Next" = seqNr
      
      "blog.typed.persistence.scaladsl.BlogData" = blog
      "blog.typed.persistence.scaladsl.PostContent" = blog
      "blog.typed.persistence.scaladsl.BlogCommand" = blog
      "blog.typed.persistence.scaladsl.AddPostDone" = blog
      "blog.typed.persistence.scaladsl.BlogEvent" = blog
    }
    serialization-identifiers {
      "blog.typed.persistence.scaladsl.BlogSerializer" = 100
    }
  }

  # For the sample, just bind to loopback and do not allow access from the network
  # the port is overridden by the logic in main class
  remote.artery.canonical.port = 0
  remote.artery.canonical.hostname = 127.0.0.1
  remote.artery.enabled = on

  cluster {
    seed-nodes = [
      "akka://ClusterSystem@127.0.0.1:2551",
      "akka://ClusterSystem@127.0.0.1:2552"]

    # Only for convenience in the sample, auto-downing should not be used for actual applications.
    # Read more here: http://doc.akka.io/docs/akka/current/scala/cluster-usage.html#auto-downing-do-not-use-
    auto-down-unreachable-after = 10s

    # Needed when running many actor systems in the same JVM
    jmx.multi-mbeans-in-same-jvm = on
  }

  # use Cassandra to store both snapshots and the events of the persistent actors
  persistence {
    journal.plugin = "cassandra-journal"
    snapshot-store.plugin = "cassandra-snapshot-store"
  }

}
